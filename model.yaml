default_model: moe-2

moe-1:
  arch: moe_1
  embed_dim: 128
  block: 4
  head: 4
  num_mha: 2
  num_ffn: 2
  steps: 2
  model_save_path: "models/TF/MoE-1.h5"

moe-2:
  arch: moe_2
  embed_dim: 128
  block: 4
  head: 8
  num_mha: 2
  num_ffn: 2
  steps: 4
  router_dim: 64
  dropout: 0.1
  model_save_path: "models/TF/MoE-2.keras"
  batch_size: 350
  learning_rate: 3.0e-6
  label_smoothing: 0.001
  weight_decay: 0.01

heavy:
  arch: transformer
  embed_dim: 256
  block: 8
  head: 8
  model_save_path: "models/TF/4G.h5"
  batch_size: 256
  learning_rate: 6.018790701331087e-05
  label_smoothing: 0.04165291567423903

nano:
  arch: transformer
  embed_dim: 32
  block: 3
  head: 4
  model_save_path: "models/TF/Nano-25K.h5"
  batch_size: 512
  learning_rate: 0.0008043670841766147
  label_smoothing: 0.000567815581294269